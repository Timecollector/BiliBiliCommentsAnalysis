## BiliBiliCommentsAnalysis

对b站弹幕、评论进行爬虫，然后使用`Word2Vec`模型将其转化为词向量进行分析

### 弹幕、评论获取

在`DataCollection.py`中定义了爬取视频aid、cid以及弹幕、评论的函数，首先需要使用**bv号**获取该视频的aid和cid，然后使用cid获取弹幕，使用aid获取评论，其中，获取弹幕的b站官方接口为`https://comment.bilibili.com/{cid}.xml`，{cid}部分需要自己填充；获取评论的接口为`https://api.bilibili.com/x/v2/reply?pn={page}&type=1&oid={aid}&sort=2`其中{page},{aid}部分需要自己填充。

最后将获取的数据保存为csv，其中**评论数据包含用户名、性别、等级、时间戳、评论**

**文件名命名方式为aid+comments+时间戳**

- demo

```python
video_bv = 'BV1p7411Y7BC'
aid, cid = get_video_id(video_bv)
get_video_danmaku(cid)
get_video_comments(aid, 1, 2000)
```

### 数据预处理

在`DataProcess.py`中定义了`text_process`函数，对数据进行了去除标点符号、去除表情、去除数字、去除空格等操作，然后定义了`词典.txt`，**其中整理了一部分b站常用的分词**，避免后续使用jieba分词时出现分词错误，但由于个人精力有限，不可避免地仍然有众多分词错误。最后，使用**百度停用词表**去除了停用词。
**对b站弹幕、评论进行分词的难点一方面在于很多用词不包含在传统的词典中，因此可能产生较多分词错误；另一方面在于评论中存在大量颜文字、特殊符号，难以一一去除**

- demo

```python
danmaku = pd.read_csv('84887919comments1650424641.8339486.csv', encoding='gb18030').iloc[:, 5]
danmaku = danmaku.apply(text_process)
for i in danmaku:
	print(i)
```

### Word2Vec

在`main.py`中，构建了Word2Vec模型，将分词后的结果转化为词向量。

如老番茄的词向量为：

```python
array([-1.2107437 , -0.1033226 ,  1.9818361 ,  0.03519016, -0.01217345,
        0.98833764,  2.7666173 ,  1.8579122 ,  1.6884342 ,  2.5897765 ,
       -0.59002656,  0.9397052 , -1.8468462 ,  1.7303164 ,  0.66788757,
        0.7514749 ,  2.6071994 ,  0.6477106 , -1.8720193 , -1.7558274 ,
        0.3031359 ,  2.4166708 , -0.07250266, -2.1228633 ,  0.49369943,
       -0.2299376 , -1.1851884 ,  0.74878716,  1.0711353 , -1.2740091 ],
      dtype=float32)
```

与老番茄最相关的20个词为：

```python
[('温柔', 0.7429916858673096),
 ('复旦之光', 0.7391597032546997),
 ('变声', 0.7284794449806213),
 ('王子', 0.7165787220001221),
 ('钢琴', 0.6986279487609863),
 ('线', 0.6952051520347595),
 ('腹肌', 0.6900023221969604),
 ('成熟', 0.689068615436554),
 ('稳重', 0.6844357848167419),
 ('拥有者', 0.6791863441467285),
 ('某幻', 0.6744824051856995),
 ('rapper', 0.6687389016151428),
 ('全能', 0.6663230657577515),
 ('出场', 0.6536276340484619),
 ('黑衣服', 0.6523473262786865),
 ('才华横溢', 0.6518454551696777),
 ('中国boy', 0.64589524269104),
 ('键盘', 0.6455495953559875),
 ('编曲', 0.6446139216423035),
 ('却', 0.643751323223114)]
```

对词向量进行降维，并可视化其中部分词语后的效果图如下:



![fig1](https://github.com/Timecollector/BiliBiliCommentsAnalysis/blob/main/fig1.png)

PS：可视化部分参考了**B站up主 五连单排一班** 的教学视频，她的b站主页为：https://space.bilibili.com/81480422/?spm_id_from=333.999.0.0

**但是，从图中可以看到，其实部分相关的词语并没有距离特别近，因此还有待进一步优化，主要问题可能是前面的分词中还有大量的无效词等等**
